We evaluate the performance of B2B throughout a series of experiments on
controlled synthetic data.
%
The purpose of these experiments is to evaluate the ability of B2B on its
ability to 1) recover causal factors when the ground truth is known and 2)
accurately predict independent and identically distributed data otherwise.

The data generating process for each experiment constructs $m=1000$ training examples
according to the model $Y = (\text{h} XS + N)F$, where $\text{h}$ is a
scalar that modulates the signal-to-noise ratio.
%
Here,
%\begin{itemize} \item $F \in \mathbb{R}^{d_x \times d_y}$ contains entries
%drawn from $\mathcal{N}(0, \sigma^2)$, \item $X \in \mathbb{R}^{m \times d_x}$
%contains rows drawn from $\mathcal{N}(0, \Sigma_X)$, \item $N \in \mathbb{R}^{m
%\times d_x}$ contains rows drawn from $\mathcal{N}(0, \Sigma_N)$, \item $S \in
%\mathbb{R}^{d_x \times d_x}$ is a binary diagonal matrix containing $n_c$ ones,
%\item $\Sigma_X = AA^\top$, where $A \in \mathbb{R}^{d_x \times d_x}$ contains
%entries drawn from $\mathcal{N}(0, \sigma^2)$, \item $\Sigma_N = BB^\top$,
%where $B \in \mathbb{R}^{d_x \times d_x}$ contains entries drawn from
%$\mathcal{N}(0, \sigma^2)$, \end{itemize}
    $F \in \mathbb{R}^{d_x \times d_y}$ contains entries drawn from
$\mathcal{N}(0, \sigma^2)$ where $\sigma^2$ is inversely proportional to $d_x$,
$X \in \mathbb{R}^{m \times d_x}$ contains rows
drawn from $\mathcal{N}(0, \Sigma_X)$, $N \in \mathbb{R}^{m \times d_x}$
contains rows drawn from $\mathcal{N}(0, \Sigma_N)$, $S \in \mathbb{R}^{d_x
\times d_x}$ is a binary diagonal matrix containing $n_c$ ones, $\Sigma_X =
AA^\top$ where $A \in \mathbb{R}^{d_x \times d_x}$ contains entries drawn from
$\mathcal{N}(0, \sigma^2)$, $\Sigma_N = BB^\top$ where $B \in \mathbb{R}^{d_x
\times d_x}$ contains entries drawn from $\mathcal{N}(0, \sigma^2)$, and the
factor $\text{h} \in \mathcal{R}_+$.

To simulate a wide range of experimental conditions, we sample 10 values in log-space for $d_x, d_y \in \left[ 10, 100 \right]$, $n_c \in \left[ 3, 63 \right]$,
$\text{h} \in \left[ 0.001, 10 \right]$. We discard the cases where $n_c > d_x$, limit $d_x, d_y$ to 100 to keep the running time under 2 hours for each condition, and average over 5 random seeds.
%
% Each condition is simulated under $5$ different random seeds.

We compare the performance of B2B against four baseline methods.
%
% To be updated

\subsubsection{Baseline models}

All baseline methods were based on the implementations of scikit-learn \citep{sklearn} and Pyrcca
\citep{bilenko2016Pyrcca}. For pedagogical purposes, we briefly summarize them below.

Forward regression consists of an $l2$-regularized "ridge" regression from the
putative causes $X$ to the observations $Y$: \begin{equation} H_{fwd} = (X^T X
+\lambda I)^{-1} X^T Y \end{equation}

Backward regression consists of an $l2$-regularized "ridge" regression from $Y$
to $X$: \begin{equation} G_{bwd} = (Y^T Y +\lambda I)^{-1} Y^T X \end{equation}

CCA finds $G_{cca}\in\mathbb{R}^{d_z, d_y}$ and $H_{cca}\in\mathbb{R}^{d_z, d_x}$
% such that
s.t.
$X$ and $Y$ are maximally correlated in a latent $Z$ space:
% \begin{equation} maxcorr(XH^T, YG^T) \end{equation}
\begin{equation} G_{cca},H_{cca} = \argmax_{G,H} corr(XH^T, YG^T) \end{equation}

% To be checked
PLS finds $G_{pls}\in\mathbb{R}^{d_z, d_y}$ and $H_{pls}\in\mathbb{R}^{d_z, d_x}$
% such that
s.t.
$X$ and $Y$ are maximally covarying in a latent $Z$ space:
% \begin{equation} maxcov(XH^T, YG^T) \end{equation}
\begin{equation} G_{pls},H_{pls} = \argmax_{G,H} \text{cov}(XH^T, YG^T) \end{equation}

We employ five-fold nested cross-validation to select the optimal number of components
for CCA and PLS. Regressions were $\ell2$-regularized with a $\lambda$ regularization
parameters fitted with the efficient leave-one-out procedure implemented in
scikit-learn RidgeCV \citep{sklearn}.

\subsubsection{Evaluating Causal Discovery from models' coefficients}

%
B2B leads to \emph{scalar} coefficients for non-causal
features. The diagonal of this matrix, $\hat S \in \mathbb{R}^{d_x}$, can thus be directly used
as a causal contribution estimate. Note that this estimate is unbiased (i.e.
zeros-centered) only if the second regression $H$ is not regularized.

In contrast, the loading coefficients of the Forward ($H_i \in \mathbb{R}^{d_y}$),
Backward ($G^i \in \mathbb{R}^{d_y}$), CCA and PLS models ($H_i \in \mathbb{R}^{d_z}$) lead to a
loading \emph{vector} for each feature $i$.
To estimate causal contribution, we must thus transform such vectors into
scalars, by e.g. taking the sum of square coefficients:
% \begin{equation}
  $\hat S_i = \sum_j {H^j_i}^2 $
% \end{equation}
Note that in such B2B cases, the estimates are thus positive and would thus bias
a second-level statistical analysis against 0.

Finally, to estimate whether each model accurately identifies causal factors independently of
their potential biases, we compute the
area-under-the-curve (AUC) across factors $AUC(S, \hat S)$.
%\begin{equation} AUC = 1 - \sum_1^m (S_k - S_{k-1}) ( \hat{S}_k +
%\hat{S}_{k-1}) / 2 \end{equation}
By definition, this AUC evaluation can only be done when ground truth labels are available, as is the case in
this synthetic setup, but not in the neuroimaging experiments below.

Figures~\ref{fig:percondition} (top) and~\ref{fig:auc_plots} (top) show the
results of this AUC evaluation. Note that the figure does not display each
feature separately, as they are randomly generated. The results show that B2B
compares favorably to other methods on these synthetic data.


\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{figures/auc_condition.pdf}
  \includegraphics[width=\linewidth]{figures/r_in_condition.pdf}
  \vspace{-4ex}
  \caption{Synthetic experiments. Average AUC (top) and Feature Importance
  $\Delta R$ (bottom) when varying experimental conditions individually.
  Higher is better. B2B compares favorably in all cases.
  \label{fig:percondition}}
\end{figure}


\subsubsection{Evaluating Causal Discovery through the reliability of held-out prediction}

In most real-world cases, $S$ is not known. Consequently, the above AUC
evaluation cannot be estimated.
To address this issue, we assess the ability of each model to reliably predict
independent and identically distributed data from $Y$, given all of the $X$
features versus all-but-one feature $X_{-i}$ (i.e. 'knock-out X'). This
procedure results in two correlation metrics $R_{full}$ and $R_{knockout}$ for
each feature (for the B2B and Backward models) for each dimension of $Y$ (for
the Forward model) or each canonical dimension of $Y$ (for CCA and PLS). The
difference $\Delta R_i = R_{full}-R_{knockout}$ indicates how much each
$X_i$ improves the prediction of
a) the target dimension (i.e. $G^iY \in \mathbb{R}$ for B2B,
b) the average across all of the dimensions $j$ of $Y$
($\frac{1}{d_y}\sum_{j}^{d_y}\Delta R_i^{j}$) for the
Forward model or
c) the average across the canonical dimensions $j$ of $Y$
($\frac{1}{d_z}\sum_{j}^{d_z}\Delta R_i^{j}$) for CCA and PLS.
We show in Appendix~\ref{appendix:feature_importance} pseudo-code to assess
feature importance for each model. For the Backward Model, feature importance
cannot be assessed as the $X$ collinearity is never
taken into account.

Figures~\ref{fig:percondition} (bottom) and~\ref{fig:auc_plots} (right, in
Appendix) show the results of this evaluation on held-out data.
Overall both the AUC and the held-out prediction reliability evaluations
show that B2B compares favorably to the baseline models.
