{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.linear_model import Ridge, LinearRegression, RidgeCV\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.linalg import pinv, svd\n",
    "from scipy.stats import ttest_1samp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthethic_data_inverse():\n",
    "    n = 10000\n",
    "    Cx = np.array([[1, -.8], [-.8, 1.]])\n",
    "    X = np.random.multivariate_normal(np.zeros(2), Cx, n)\n",
    "    E = np.eye(2)\n",
    "    N = np.random.randn(n, 2) * 0\n",
    "    F = np.array([[1.], [3]])\n",
    "    Y = (X @ E + N) @ F\n",
    "    return scale(X), scale(Y), E\n",
    "\n",
    "\n",
    "def syntethic_data_high_dim(seed=0):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    n = 1000  # number of samples\n",
    "    dim_x = 100  # dimensionality of X\n",
    "    dim_y = 101\n",
    "    selected = .10  # percentage of features selected in E\n",
    "\n",
    "    Cx = np.random.randn(dim_x, dim_x)\n",
    "    Cx = Cx.dot(Cx.T) / dim_x  # sym pos-semidefin\n",
    "\n",
    "    X = np.random.multivariate_normal(np.zeros(dim_x), Cx, n)\n",
    "    N = np.random.randn(n, dim_x)\n",
    "    F = np.random.randn(dim_y, dim_x)\n",
    "    E = np.eye(dim_x)\n",
    "    E = np.diag(np.random.rand(dim_x) < selected)\n",
    "    Y = (X @ E + N) @ F.T\n",
    "\n",
    "    return scale(X), scale(Y), E\n",
    "\n",
    "\n",
    "def ridge_cv(X, Y, alphas, independent_alphas=False):\n",
    "    \"\"\"\n",
    "    Similar to sklearn RidgeCV but\n",
    "    (1) can optimize a different alpha for each column of Y (independent_alphas=True)\n",
    "    (2) return leave-one-out Y_hat\n",
    "    \"\"\"\n",
    "    if isinstance(alphas, (float, int)):\n",
    "        alphas = np.array([alphas, ], np.float64)\n",
    "    n, n_x = X.shape\n",
    "    n, n_y = Y.shape\n",
    "    # Decompose X\n",
    "    U, s, _ = svd(X, full_matrices=0)\n",
    "    v = s**2\n",
    "    UY = U.T @ Y\n",
    "\n",
    "    # For each alpha, solve leave-one-out error coefs\n",
    "    cv_duals = np.zeros((len(alphas), n, n_y))\n",
    "    cv_errors = np.zeros((len(alphas), n, n_y))\n",
    "    for alpha_idx, alpha in enumerate(alphas):\n",
    "        # Solve\n",
    "        w = ((v + alpha) ** -1) - alpha ** -1\n",
    "        c = U @ np.diag(w) @ UY + alpha ** -1 * Y\n",
    "        cv_duals[alpha_idx] = c\n",
    "\n",
    "        # compute diagonal of the matrix: dot(Q, dot(diag(v_prime), Q^T))\n",
    "        G_diag = (w * U ** 2).sum(axis=-1) + alpha ** -1\n",
    "        error = c / G_diag[:, np.newaxis]\n",
    "        cv_errors[alpha_idx] = error\n",
    "\n",
    "    # identify best alpha for each column of Y independently\n",
    "    if independent_alphas:\n",
    "        best_alphas = (cv_errors ** 2).mean(axis=1).argmin(axis=0)\n",
    "        duals = np.transpose([cv_duals[b, :, i]\n",
    "                              for i, b in enumerate(best_alphas)])\n",
    "        cv_errors = np.transpose([cv_errors[b, :, i]\n",
    "                                  for i, b in enumerate(best_alphas)])\n",
    "    else:\n",
    "        _cv_errors = cv_errors.reshape(len(alphas), -1)\n",
    "        best_alphas = (_cv_errors ** 2).mean(axis=1).argmin(axis=0)\n",
    "        duals = cv_duals[best_alphas]\n",
    "        cv_errors = cv_errors[best_alphas]\n",
    "\n",
    "    coefs = duals.T @ X\n",
    "    Y_hat = Y - cv_errors\n",
    "    return coefs, best_alphas, Y_hat\n",
    "\n",
    "\n",
    "def trunkated_ols(X, Y):\n",
    "    pca = PCA('mle').fit(X)\n",
    "    Xt = pca.inverse_transform(pca.transform(X))\n",
    "    coef = pinv(Xt.T @ Xt) @ Xt.T @ Y\n",
    "    return coef\n",
    "\n",
    "\n",
    "def jrr(X, Y, alphas=np.logspace(-5, 5, 20)):\n",
    "    \"\"\"\n",
    "    G = ls(Y, X)\n",
    "    H = ls(X, YG)\n",
    "    E = diag(H)\n",
    "    \"\"\"\n",
    "    G, best_alphas, X_hat = ridge_cv(Y, X, alphas, independent_alphas=True)\n",
    "    H, best_alphas, X_hat = ridge_cv(X, X_hat, alphas)\n",
    "    E_hat = np.diag(H)\n",
    "    return E_hat\n",
    "\n",
    "\n",
    "def jrr_pca(X, Y, alphas=np.logspace(-5, 5, 20)):\n",
    "    G, best_alphas, X_hat = ridge_cv(Y, X, alphas, independent_alphas=True)\n",
    "    H = trunkated_ols(X, X_hat)\n",
    "    E_hat = np.diag(H)\n",
    "    return E_hat\n",
    "\n",
    "\n",
    "def jrr2(X, Y, alphas=np.logspace(-5, 5, 20)):\n",
    "    \"\"\"\n",
    "    for i in dim_x:\n",
    "        g_i = ls([X_j, Y], X_i), where j is all columns but i\n",
    "        x_hat_i = [X_j, Y] @ g_i\n",
    "    H = ls(X, X_hat)\n",
    "    E = diag(H)\n",
    "    \"\"\"\n",
    "\n",
    "    dim_x = len(X.T)\n",
    "\n",
    "    X_hat = np.zeros_like(X)\n",
    "    for i in trange(dim_x):\n",
    "        not_i = [j for j in range(dim_x) if j != i]\n",
    "        XY = np.c_[X[:, not_i], Y]\n",
    "        _, best, X_hat[:, [i, ]] = ridge_cv(XY, X[:, [i, ]], alphas)\n",
    "    H, _, _ = ridge_cv(X, X_hat, alphas)\n",
    "    E_hat = np.diag(H)\n",
    "    return E_hat\n",
    "\n",
    "\n",
    "def jrr2_pca(X, Y, alphas=np.logspace(-5, 5, 20)):\n",
    "    dim_x = len(X.T)\n",
    "\n",
    "    X_hat = np.zeros_like(X)\n",
    "    for i in trange(dim_x):\n",
    "        not_i = [j for j in range(dim_x) if j != i]\n",
    "        XY = np.c_[X[:, not_i], Y]\n",
    "        _, best, X_hat[:, [i, ]] = ridge_cv(XY, X[:, [i, ]], alphas)\n",
    "    H = trunkated_ols(X, X_alphas)\n",
    "    E_hat = np.diag(H)\n",
    "    return E_hat\n",
    "\n",
    "\n",
    "def jrr3(X, Y, alphas=np.logspace(-5, 5, 20)):\n",
    "    dim_x = len(X.T)\n",
    "    X_hat = np.zeros_like(X)\n",
    "    for i in trange(dim_x):\n",
    "        not_i = [j for j in range(dim_x) if j != i]\n",
    "        XY = np.c_[X[:, not_i], Y]\n",
    "        X_hat[:, [i, ]] = ridge_cv(XY, X[:, [i, ]], alphas)[2]\n",
    "        X_hat[:, [i, ]] += ridge_cv(Y, X[:, [i, ]], alphas)[2]\n",
    "        X_hat[:, [i, ]] -= ridge_cv(X[:, not_i], X[:, [i, ]], alphas)[2]\n",
    "    H, _, _ = ridge_cv(X, X_hat, alphas)\n",
    "    E_hat = np.diag(H)\n",
    "    return E_hat\n",
    "\n",
    "\n",
    "def jrr3_pca(X, Y, alphas=np.logspace(-5, 5, 20)):\n",
    "    X_hat = np.zeros_like(X)\n",
    "    for i in trange(dim_x):\n",
    "        not_i = [j for j in range(dim_x) if j != i]\n",
    "        XY = np.c_[X[:, not_i], Y]\n",
    "        X_hat[:, [i, ]] = ridge_cv(XY, X[:, [i, ]], alphas)[2]\n",
    "        X_hat[:, [i, ]] += ridge_cv(Y, X[:, [i, ]], alphas)[2]\n",
    "        X_hat[:, [i, ]] -= ridge_cv(X[:, not_i], X[:, [i, ]], alphas)[2]\n",
    "    H = trunkated_ols(X, X_hat)\n",
    "    E_hat = np.diag(H)\n",
    "    return E_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 181.56it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 190.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jrr <0 [-0.27287689  1.27277789]\n",
      "jrr2 not<0 [0.99999963 0.99999995]\n",
      "jrr3 not<0 [0.72722458 2.27287653]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X, Y, E = synthethic_data_inverse()\n",
    "\n",
    "print('jrr <0', jrr(X, Y, alphas=1e-4))  # negative coeff issue\n",
    "print('jrr2 not<0', jrr2(X, Y, alphas=1e-4))  # great\n",
    "print('jrr3 not<0', jrr3(X, Y, alphas=1e-4))  # great, although weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.41it/s]\n",
      " 37%|███▋      | 37/100 [00:06<00:10,  6.01it/s]"
     ]
    }
   ],
   "source": [
    "X, Y, E = syntethic_data_high_dim()\n",
    "\n",
    "alphas = np.logspace(-4, 4, 20)\n",
    "plt.plot(np.diag(E), label='E')\n",
    "plt.plot(jrr(X, Y, alphas=alphas), label='jrr')  # ok\n",
    "plt.plot(jrr2(X, Y, alphas=alphas), label='jrr2')  # completely fails\n",
    "plt.plot(jrr3(X, Y, alphas=alphas), label='jrr3')  # ok\n",
    "plt.axhline(0, color='k', label='chance')\n",
    "plt.legend()\n",
    "plt.ylim(-.05, .07)\n",
    "\n",
    "# notice that jrr and jrr3 work but have a slight positive bias due to second regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The svd trunkation for the last regression seems to be a good way not to have a bias.\n",
    "\n",
    "# it s unsurprisingly a bit less good than with the bias\n",
    "alphas = np.logspace(-4, 4, 20)\n",
    "plt.plot(np.diag(E), label='E')\n",
    "plt.plot(jrr_pca(X, Y, alphas=alphas), label='jrr')\n",
    "plt.plot(jrr3_pca(X, Y, alphas=alphas), label='jrr3')\n",
    "plt.axhline(0, color='k', label='chance')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
