{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%retina` not found.\n"
     ]
    }
   ],
   "source": [
    "%retina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from base import B2B, Forward, CrossDecomp, Backward, r_score\n",
    "from sklearn.cross_decomposition import CCA, PLSRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import pickle\n",
    "import time\n",
    "import submitit\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Synthetic(object):\n",
    "    def __init__(self,\n",
    "                 dim_x=50,         # number of features\n",
    "                 dim_y=30,         # number of sensors\n",
    "                 nc=5,             # number of selected features\n",
    "                 snr=1.0,          # signal-to-noise ratio\n",
    "                 nonlinear=False):  # number of selected features\n",
    "        \n",
    "        # linear transformation\n",
    "        self.F = np.random.randn(dim_x, dim_y) / np.sqrt(dim_x)\n",
    "\n",
    "        # masking transformation\n",
    "        self.E = np.array([0] * (dim_x - nc) + [1] * (nc))\n",
    "\n",
    "        # features covariance\n",
    "        self.cov_X = np.random.randn(dim_x, dim_x) / np.sqrt(dim_x)\n",
    "        self.cov_X = self.cov_X @ self.cov_X.T\n",
    "        \n",
    "        # noise covariance\n",
    "        self.cov_N = np.random.randn(dim_x, dim_x) / np.sqrt(dim_x)\n",
    "        self.cov_N = self.cov_N @ self.cov_N.T\n",
    "        \n",
    "        self.dim_x = dim_x\n",
    "        self.dim_y = dim_y\n",
    "        self.nonlinear = nonlinear\n",
    "        self.snr = snr\n",
    "\n",
    "    def sample(self, n_samples=1000):\n",
    "        X = np.random.multivariate_normal(np.zeros(self.dim_x),\n",
    "                                          self.cov_X, n_samples)\n",
    "        N = np.random.multivariate_normal(np.zeros(self.dim_x),\n",
    "                                          self.cov_N, n_samples)\n",
    "\n",
    "        # observed sensor data\n",
    "        Y = (self.snr * X @ np.diag(self.E) + N) @ self.F\n",
    "\n",
    "        if self.nonlinear:\n",
    "            Y = 1. / (1. + np.exp(-Y))\n",
    "\n",
    "        # return inputs, outputs, and solution\n",
    "        return scale(X), scale(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridCCA(n_components):\n",
    "    grid = dict(n_components=np.unique(np.floor(np.linspace(1, n_components, 10)).astype(int)))\n",
    "    return CrossDecomp(GridSearchCV(CCA(max_iter=1000), grid, cv=5))\n",
    "\n",
    "\n",
    "def GridPLS(n_components):\n",
    "    grid = dict(n_components=np.unique(np.floor(np.linspace(1, n_components, 10)).astype(int)))\n",
    "    return CrossDecomp(GridSearchCV(PLSRegression(max_iter=1000), grid, cv=5))\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"B2B\": B2B,\n",
    "    \"Forward\": Forward,\n",
    "    \"Backward\": Backward,\n",
    "    \"GridCCA\": GridCCA,\n",
    "    \"GridPLS\": GridPLS,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(args=dict()):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    n_samples = args.get('n_samples', 1000)\n",
    "    dim_x = args.get('dim_x', 100)\n",
    "    dim_y = args.get('dim_y', 100)\n",
    "    snr = args.get('.snr', 1)\n",
    "    nc = args.get('nc', 5)\n",
    "    nonlinear = args.get('nonlinear', 0)\n",
    "    n_seeds = args.get('n_seeds', 10)\n",
    "        \n",
    "    results = []\n",
    "\n",
    "    for seed in range(n_seeds):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Make environment\n",
    "        synthetic = Synthetic(dim_x, dim_y, nc,\n",
    "                              snr, nonlinear)\n",
    "\n",
    "        # Make data\n",
    "        X_train, Y_train = synthetic.sample(n_samples)\n",
    "        X_test, Y_test = synthetic.sample(n_samples * 10)\n",
    "\n",
    "        for m, Model in models.items():\n",
    "            \n",
    "            model = Model(min(dim_x, dim_y)) if 'Grid' in m else Model()\n",
    "\n",
    "            # fit model on training data\n",
    "            start = time.time()\n",
    "            model.fit(X_train, Y_train)\n",
    "            duration = time.time() - start\n",
    "\n",
    "            # Estimate effect from model parameters\n",
    "            auc = roc_auc_score(synthetic.E, model.E_)\n",
    "\n",
    "            # Estimate effect from prediction reliability on held-out data\n",
    "            r_full = model.score(X_test, Y_test)\n",
    "            r_ko = model.score_knockout(X_test, Y_test)\n",
    "\n",
    "            r_delta = r_full - r_ko\n",
    "\n",
    "            r_in = r_delta[synthetic.E==1].mean()\n",
    "            r_out = r_delta[synthetic.E==0].mean()\n",
    "\n",
    "            # Store results\n",
    "            result = dict(dim_x=dim_x, dim_y=dim_y, nc=nc, snr=snr, \n",
    "                          nonlinear=nonlinear)\n",
    "            result[\"model\"] = m\n",
    "            result[\"seed\"] = seed\n",
    "            result[\"r_in\"] = r_in\n",
    "            result[\"r_out\"] = r_out\n",
    "            result[\"auc\"] = auc\n",
    "            result['id'] = '_'.join(map(str, [dim_x, dim_y, nc, snr, nonlinear, \n",
    "                                              m, seed]))\n",
    "            result['duration'] = duration\n",
    "            print(result)\n",
    "            results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = submitit.AutoExecutor(folder='./synthetic/')\n",
    "executor.update_parameters(timeout_min=60, \n",
    "                           partition='learnfair,uninterrupted,scavenge',\n",
    "                           constraint='pascal', cpus_per_task=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jobs = list()\n",
    "snrs = np.logspace(-3, 3, 10)\n",
    "dim_xs = np.logspace(1, 3, 10).astype(int)\n",
    "dim_ys = np.logspace(1, 3, 10).astype(int)\n",
    "ncs = np.logspace(0, 2, 10).astype(int)\n",
    "\n",
    "for snr, dim_x, dim_y, nc in product(snrs, dim_xs, dim_ys, ncs):\n",
    "    args = dict(snr=snr, n_seeds=5,\n",
    "                dim_x=dim_x, dim_y=dim_y, nc=nc)\n",
    "    jobs.append([args,])\n",
    "jobs = executor.map_array(run, *zip(*jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = jobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j.re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "results = list()\n",
    "for job in jobs:\n",
    "    print(len(results))\n",
    "    try:\n",
    "        results.extend(job.results())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
